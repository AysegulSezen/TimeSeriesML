{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0162197c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-26T10:25:04.393110Z",
     "iopub.status.busy": "2024-03-26T10:25:04.392481Z",
     "iopub.status.idle": "2024-03-26T10:25:20.968136Z",
     "shell.execute_reply": "2024-03-26T10:25:20.966879Z"
    },
    "papermill": {
     "duration": 16.582967,
     "end_time": "2024-03-26T10:25:20.970574",
     "exception": false,
     "start_time": "2024-03-26T10:25:04.387607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "from sklearn import linear_model\n",
    "import os\n",
    "import csv\n",
    "\n",
    "#neural network - keras package\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#SVM package\n",
    "from sklearn import svm\n",
    "\n",
    "#1- Getting and Preparing Data\n",
    "# 1.1 - Getting data into dataframes from csv files\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        fileFullName=os.path.join(dirname, filename)\n",
    "        if (filename=='train.csv'):\n",
    "            train_data = pd.read_csv(fileFullName)\n",
    "        elif (filename=='test.csv'):\n",
    "            test_data = pd.read_csv(fileFullName)\n",
    "        else:\n",
    "            gender_data = pd.read_csv(fileFullName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e21562",
   "metadata": {
    "papermill": {
     "duration": 0.001965,
     "end_time": "2024-03-26T10:25:20.975119",
     "exception": false,
     "start_time": "2024-03-26T10:25:20.973154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After getting data, we clean train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573de07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T10:25:20.981710Z",
     "iopub.status.busy": "2024-03-26T10:25:20.980714Z",
     "iopub.status.idle": "2024-03-26T10:25:21.019309Z",
     "shell.execute_reply": "2024-03-26T10:25:21.018301Z"
    },
    "papermill": {
     "duration": 0.044648,
     "end_time": "2024-03-26T10:25:21.021886",
     "exception": false,
     "start_time": "2024-03-26T10:25:20.977238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[ 3.      1.     22.      1.      0.      7.25  ]\n",
      " [ 1.      0.     38.      1.      0.     71.2833]\n",
      " [ 3.      0.     26.      0.      0.      7.925 ]\n",
      " ...\n",
      " [ 3.      0.     20.      1.      2.     23.45  ]\n",
      " [ 1.      1.     26.      0.      0.     30.    ]\n",
      " [ 3.      1.     32.      0.      0.      7.75  ]]\n"
     ]
    }
   ],
   "source": [
    "# 1.2 - Cleaning training data\n",
    "train_data['Age'] = train_data['Age'].fillna(20)\n",
    "\n",
    "cln_train_data=train_data[['Pclass','Sex','Age','SibSp','Parch','Fare']]\n",
    "cln_data=cln_train_data[cln_train_data.isna().any(axis=1)]\n",
    "\n",
    "train_data.loc[train_data['Sex']=='male','Sex']=1\n",
    "train_data.loc[train_data['Sex']=='female','Sex']=0\n",
    "\n",
    "X_train = train_data[['Pclass','Sex','Age','SibSp','Parch','Fare']]\n",
    "y_train = train_data['Survived']\n",
    "\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "print('X_train:',X_train)\n",
    "\n",
    "# 1.3 - Cleaning test data\n",
    "test_data.loc[test_data['Sex']=='male','Sex']=1\n",
    "test_data.loc[test_data['Sex']=='female','Sex']=0\n",
    "# Changing Nan value\n",
    "test_data['Age'] = test_data['Age'].fillna(20)\n",
    "test_data['Fare']= test_data['Fare'].fillna(50)\n",
    "\n",
    "cln_test_data=test_data[['Pclass','Sex','Age','SibSp','Parch','Fare']]\n",
    "cln_data1=cln_test_data[cln_test_data.isna().any(axis=1)]\n",
    "\n",
    "X_test = test_data[['Pclass','Sex','Age','SibSp','Parch','Fare']]\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "#y_test = test_data['Survived']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edc390",
   "metadata": {
    "papermill": {
     "duration": 0.002124,
     "end_time": "2024-03-26T10:25:21.026672",
     "exception": false,
     "start_time": "2024-03-26T10:25:21.024548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can use logistic regression, machine learning or SVM algorithm to predict test data. I used 3 of them and then commented 2 of them after seeing their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70fe48e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T10:25:21.033162Z",
     "iopub.status.busy": "2024-03-26T10:25:21.032788Z",
     "iopub.status.idle": "2024-03-26T10:25:38.139920Z",
     "shell.execute_reply": "2024-03-26T10:25:38.138580Z"
    },
    "papermill": {
     "duration": 17.113665,
     "end_time": "2024-03-26T10:25:38.142597",
     "exception": false,
     "start_time": "2024-03-26T10:25:21.028932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n",
      "passa Id: [892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309]\n",
      "predictions: 418\n",
      "passa Id: 418\n",
      "dfP shape: (418, 2)\n"
     ]
    }
   ],
   "source": [
    "#2.1- Running machine learning algorithm - logistic regr.\n",
    "#model = linear_model.LogisticRegression()\n",
    "#model.fit(X_train,y_train)\n",
    "#print(model.coef_)\n",
    "\n",
    "#2.2 Running machine learning algorithm - neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(12,input_shape=(6,),activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "#2.3 Running machine learning algorithm - SVM \n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3 Prediction\n",
    "#predictions = model.predict(X_test)\n",
    "#predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "#plt.scatter(y_test, predictions)\n",
    "print('predictions:',predictions)\n",
    "print('passa Id:',test_data['PassengerId'].tolist())\n",
    "\n",
    "print('predictions:',len(predictions))\n",
    "print('passa Id:',len(test_data['PassengerId'].tolist()))\n",
    "\n",
    "\n",
    "dfP=pd.DataFrame({ 'PassengerId': test_data['PassengerId'].tolist(),\n",
    "                   'Survived':  predictions.tolist()\n",
    "                    })\n",
    "\n",
    "print('dfP shape:',dfP.shape)\n",
    "dfP.to_csv('/kaggle/working/predictAysegul.csv',index=False)\n",
    "\n",
    "f1 = open('/kaggle/working/predictAysegul.csv','r')\n",
    "#print('file:',f1.read())\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessio"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39.339345,
   "end_time": "2024-03-26T10:25:39.672995",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-26T10:25:00.333650",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
